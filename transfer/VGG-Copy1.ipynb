{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hispanic-smith",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import itertools\n",
    "import keras\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img \n",
    "from keras.models import Sequential \n",
    "from keras import optimizers\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import Dropout, Flatten, Dense \n",
    "from keras import applications \n",
    "from keras.utils.np_utils import to_categorical \n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "import math \n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "proprietary-string",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "pending-default",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Default dimensions we found online\n",
    "img_width, img_height = 224, 224 \n",
    " \n",
    "#Create a bottleneck file\n",
    "top_model_weights_path = 'bottleneck_fc.h5'\n",
    "# oading up our datasets\n",
    "train_data_dir = 'data3/train' \n",
    "validation_data_dir = 'data3/val' \n",
    "test_data_dir = 'data3/test'\n",
    " \n",
    "# number of epochs to train top model \n",
    "epochs = 3 #this has been changed after multiple model run \n",
    "# batch size used by flow_from_directory and predict_generator \n",
    "batch_size = 16 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "compatible-father",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading vgc16 model\n",
    "vgg16 = applications.VGG16(include_top=False, weights='imagenet')\n",
    "datagen = ImageDataGenerator(rescale=1. / 255) \n",
    "#needed to create the bottleneck .npy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bearing-infrastructure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#__this can take an hour and half to run so only run it once. \\n#once the npy files have been created, no need to run again. Convert this cell to a code cell to run.__\\nstart = datetime.datetime.now()\\n \\ngenerator = datagen.flow_from_directory( \\n    train_data_dir, \\n    target_size=(img_width, img_height), \\n    batch_size=batch_size, \\n    class_mode=None, \\n    shuffle=False) \\n \\nnb_train_samples = len(generator.filenames) \\nnum_classes = len(generator.class_indices) \\n \\npredict_size_train = int(math.ceil(nb_train_samples / batch_size)) \\n \\nbottleneck_features_train = vgg16.predict_generator(generator, predict_size_train) \\n \\nnp.save('bottleneck_features_train.npy', bottleneck_features_train)\\nend= datetime.datetime.now()\\nelapsed= end-start\\nprint ('Time: ', elapsed)\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#__this can take an hour and half to run so only run it once. \n",
    "#once the npy files have been created, no need to run again. Convert this cell to a code cell to run.__\n",
    "start = datetime.datetime.now()\n",
    " \n",
    "generator = datagen.flow_from_directory( \n",
    "    train_data_dir, \n",
    "    target_size=(img_width, img_height), \n",
    "    batch_size=batch_size, \n",
    "    class_mode=None, \n",
    "    shuffle=False) \n",
    " \n",
    "nb_train_samples = len(generator.filenames) \n",
    "num_classes = len(generator.class_indices) \n",
    " \n",
    "predict_size_train = int(math.ceil(nb_train_samples / batch_size)) \n",
    " \n",
    "bottleneck_features_train = vgg16.predict_generator(generator, predict_size_train) \n",
    " \n",
    "np.save('bottleneck_features_train.npy', bottleneck_features_train)\n",
    "end= datetime.datetime.now()\n",
    "elapsed= end-start\n",
    "print ('Time: ', elapsed)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "professional-detail",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 58394 images belonging to 77 classes.\n"
     ]
    }
   ],
   "source": [
    "#training data\n",
    "generator_top = datagen.flow_from_directory( \n",
    "   train_data_dir, \n",
    "   target_size=(img_width, img_height), \n",
    "   batch_size=batch_size, \n",
    "   class_mode='categorical', \n",
    "   shuffle=False) \n",
    " \n",
    "nb_train_samples = len(generator_top.filenames) \n",
    "num_classes = len(generator_top.class_indices) \n",
    " \n",
    "# load the bottleneck features saved earlier \n",
    "train_data = np.load('bottleneck_features_train.npy') \n",
    " \n",
    "# get the class labels for the training data, in the original order \n",
    "train_labels = generator_top.classes \n",
    " \n",
    "# convert the training labels to categorical vectors \n",
    "train_labels = to_categorical(train_labels, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "canadian-treat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19465 images belonging to 76 classes.\n"
     ]
    }
   ],
   "source": [
    "#validation data\n",
    "generator_val = datagen.flow_from_directory( \n",
    "   validation_data_dir, \n",
    "   target_size=(img_width, img_height), \n",
    "   batch_size=batch_size, \n",
    "   class_mode='categorical', \n",
    "   shuffle=False) \n",
    " \n",
    "nb_train_samples = len(generator_top.filenames) \n",
    "num_classes = len(generator_top.class_indices) \n",
    " \n",
    "# load the bottleneck features saved earlier \n",
    "validation_data = np.load('bottleneck_features_train.npy') \n",
    " \n",
    "# get the class labels for the training data, in the original order \n",
    "validation_labels = generator_top.classes \n",
    " \n",
    "# convert the training labels to categorical vectors \n",
    "validation_labels = to_categorical(validation_labels, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "seven-confirmation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19465 images belonging to 76 classes.\n"
     ]
    }
   ],
   "source": [
    "#test data\n",
    "generator_test = datagen.flow_from_directory( \n",
    "   test_data_dir, \n",
    "   target_size=(img_width, img_height), \n",
    "   batch_size=batch_size, \n",
    "   class_mode='categorical', \n",
    "   shuffle=False) \n",
    " \n",
    "nb_train_samples = len(generator_top.filenames) \n",
    "num_classes = len(generator_top.class_indices) \n",
    " \n",
    "# load the bottleneck features saved earlier \n",
    "test_data = np.load('bottleneck_features_train.npy') \n",
    " \n",
    "# get the class labels for the training data, in the original order \n",
    "test_labels = generator_top.classes \n",
    " \n",
    "# convert the training labels to categorical vectors \n",
    "test_labels = to_categorical(test_labels, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-coordination",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "presidential-providence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3650/3650 [==============================] - 39s 11ms/step - loss: 3.6980 - acc: 0.1734 - val_loss: 3.1852 - val_acc: 0.2112\n",
      "Epoch 2/3\n",
      "3650/3650 [==============================] - 33s 9ms/step - loss: 3.3096 - acc: 0.2125 - val_loss: 3.0772 - val_acc: 0.2518\n",
      "Epoch 3/3\n",
      "3650/3650 [==============================] - 32s 9ms/step - loss: 3.2220 - acc: 0.2241 - val_loss: 3.0233 - val_acc: 0.2555\n"
     ]
    }
   ],
   "source": [
    "#This is the best model we found. For additional models, check out I_notebook.ipynb\n",
    "#start = datetime.datetime.now()\n",
    "model = Sequential() \n",
    "model.add(Flatten(input_shape=train_data.shape[1:])) \n",
    "model.add(Dense(100, activation=keras.layers.LeakyReLU(alpha=0.3))) \n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Dense(50, activation=keras.layers.LeakyReLU(alpha=0.3))) \n",
    "model.add(Dropout(0.3)) \n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "   optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "   metrics=['acc'])\n",
    "history = model.fit(train_data, train_labels, \n",
    "   epochs=3,\n",
    "   batch_size=batch_size, \n",
    "   validation_data=(validation_data, validation_labels))\n",
    "model.save_weights(top_model_weights_path)\n",
    "(eval_loss, eval_accuracy) = model.evaluate( \n",
    "    validation_data, validation_labels, batch_size=batch_size,     verbose=1)\n",
    "print(\"[INFO] accuracy: {:.2f}%\".format(eval_accuracy * 100)) \n",
    "print(\"[INFO] Loss: {}\".format(eval_loss)) \n",
    "#end= datetime.datetime.now()\n",
    "#elapsed= end-start\n",
    "#print ('Time: ', elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-helen",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-property",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
